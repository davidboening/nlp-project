{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Downloads and Preprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Webpage: https://nlp.stanford.edu/projects/jesc/\n",
      "Paper  : https://arxiv.org/abs/1710.10639\n",
      "Summary: Japanese-English Subtitle Corpus (2.8M sentences)\n",
      "skipped: jesc.csv file already exists!\n"
     ]
    }
   ],
   "source": [
    "from utils.dataset import JESC\n",
    "\n",
    "JESC.info()\n",
    "JESC.create_csv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Webpage : https://github.com/venali/BilingualCorpus/\n",
      "Summary : a large scale corpus of manually translated Japanese sentences\n",
      "          extracted from Wikipedia's Kyoto Articles (~500k sentences)\n",
      "skipped: wiki_corpus.csv file already exists!\n"
     ]
    }
   ],
   "source": [
    "from utils.dataset import WikiCorpus\n",
    "\n",
    "WikiCorpus.info()\n",
    "WikiCorpus.create_csv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Webpage    : https://opus.nlpl.eu/Tatoeba.php\n",
      "Webpage(HF): https://huggingface.co/datasets/tatoeba\n",
      "Summary    : a collection of sentences from https://tatoeba.org/en/, contains\n",
      "             over 400 languages ([en-ja] 200k sentences)\n",
      "skipped: tatoeba.csv file already exists!\n"
     ]
    }
   ],
   "source": [
    "from utils.dataset import Tatoeba\n",
    "\n",
    "Tatoeba.info()\n",
    "Tatoeba.create_csv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Webpage: https://huggingface.co/datasets/snow_simplified_japanese_corpus\n",
      "Summary: Japanese-English sentence pairs, all Japanese sentences have\n",
      "         a simplified counterpart (85k(x2) sentences)\n",
      "skipped: snow_simplified.csv file already exists!\n"
     ]
    }
   ],
   "source": [
    "from utils.dataset import SnowSimplified\n",
    "\n",
    "SnowSimplified.info()\n",
    "SnowSimplified.create_csv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Webpage: https://huggingface.co/datasets/Amani27/massive_translation_dataset\n",
      "Summary: dataset derived from AmazonScience/MASSIVE for translation\n",
      "         (16k sentences in 10 languages)\n",
      "skipped: massive_translation.csv file already exists!\n"
     ]
    }
   ],
   "source": [
    "from utils.dataset import MassiveTranslation\n",
    "\n",
    "MassiveTranslation.info()\n",
    "MassiveTranslation.create_csv()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Combining Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tokenizers import processors\n",
    "from transformers import AutoTokenizer\n",
    "\n",
    "source_lng = \"ja\"\n",
    "\n",
    "if source_lng == \"en\": \n",
    "    target_lng = \"ja\"\n",
    "    encoder = \"bert-base-uncased\"\n",
    "    decoder = \"rinna/japanese-gpt2-small\" \n",
    "else: \n",
    "    target_lng = \"en\"\n",
    "    encoder = \"cl-tohoku/bert-base-japanese-v3\"\n",
    "    decoder = \"gpt2\"\n",
    "\n",
    "encoder_tokenizer = AutoTokenizer.from_pretrained(encoder, use_fast=True)\n",
    "decoder_tokenizer = AutoTokenizer.from_pretrained(decoder, use_fast=True)\n",
    "if decoder_tokenizer.pad_token_id is None:\n",
    "    decoder_tokenizer.pad_token_id = decoder_tokenizer.eos_token_id\n",
    "\n",
    "# adds an EOS token at the end of each sentence\n",
    "decoder_tokenizer._tokenizer.post_processor = processors.TemplateProcessing(\n",
    "    single=\"$A \" + decoder_tokenizer.eos_token,\n",
    "    special_tokens=[(decoder_tokenizer.eos_token, decoder_tokenizer.eos_token_id)],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "06a3ab0848ca4ffe93588ee47d1f06ae",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map (num_proc=6):   0%|          | 0/100000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7f98effbf0b24415aa88b7b4935f0372",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter (num_proc=6):   0%|          | 0/100000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sampling: 124 out of 100000\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3219330f75e44aafbb644777fc0a1146",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map (num_proc=6):   0%|          | 0/2801388 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4fd2d20c78ae466d988e343a023c1d89",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter (num_proc=6):   0%|          | 0/2801388 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sampling: using all data (27)\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bfb727c7a62d4587bbdf3c4e7b722415",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Saving the dataset (0/1 shards):   0%|          | 0/151 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from utils.dataset import EnJaDatasetMaker, EnJaDatasetSample\n",
    "\n",
    "dataset = EnJaDatasetMaker.prepare_dataset(\n",
    "    \"ja-en-test-1\",\n",
    "    [\n",
    "        # lower is inclusive, upper is exclusive (0, 32) -> [0, 31]\n",
    "        EnJaDatasetSample(SnowSimplified    ,  124, (0, 64)),\n",
    "        EnJaDatasetSample(MassiveTranslation,   50, (0, 32)),\n",
    "    ],\n",
    "    source_language=source_lng,\n",
    "    encoder_tokenizer=encoder_tokenizer,\n",
    "    decoder_tokenizer=decoder_tokenizer,\n",
    "    num_proc=6,\n",
    "    seed=42\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['target', 'source', 'length', 'input_ids', 'attention_mask', 'labels'],\n",
       "    num_rows: 151\n",
       "})"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = EnJaDatasetMaker.load_dataset(\"ja-en-test-1\")\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'target': \"don 't rely too much on others .\",\n",
       " 'source': 'あまり他人には頼ってはいけない。',\n",
       " 'length': tensor(12),\n",
       " 'input_ids': tensor([[    2, 13903, 17606,   461,   465, 26960,   456,   465, 16562, 12494,\n",
       "            385,     3]]),\n",
       " 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]]),\n",
       " 'labels': tensor([[ 9099,   705,    83,  8814,  1165,   881,   319,  1854,   764, 50256]])}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[0]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
