{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import os\n",
    "os.environ[\"HF_HOME\"] = r\"./.cache\"\n",
    "\n",
    "from transformers import EncoderDecoderModel, AutoTokenizer, GenerationConfig, Seq2SeqTrainer, Seq2SeqTrainingArguments\n",
    "from tokenizers import processors\n",
    "import evaluate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Encoders\n",
    "    - BERT_JA : `cl-tohoku/bert-base-japanese-v3`\n",
    "    - BERT_EN : `bert-base-uncased`, `prajjwal1/bert-tiny`\n",
    "- Decorders\n",
    "    - GPT_JA : `rinna/japanese-gpt2-xsmall`\n",
    "    - GPT_EN : `gpt2`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of GPT2LMHeadModel were not initialized from the model checkpoint at gpt2 and are newly initialized: ['h.11.ln_cross_attn.bias', 'h.8.crossattention.c_proj.weight', 'h.5.crossattention.q_attn.weight', 'h.2.crossattention.c_attn.weight', 'h.3.crossattention.q_attn.bias', 'h.3.crossattention.c_proj.weight', 'h.4.ln_cross_attn.weight', 'h.3.crossattention.c_proj.bias', 'h.2.ln_cross_attn.weight', 'h.11.crossattention.c_proj.weight', 'h.10.crossattention.c_proj.weight', 'h.2.crossattention.q_attn.bias', 'h.0.crossattention.q_attn.weight', 'h.0.crossattention.c_attn.weight', 'h.10.ln_cross_attn.weight', 'h.3.ln_cross_attn.bias', 'h.5.ln_cross_attn.weight', 'h.8.crossattention.c_attn.bias', 'h.4.crossattention.c_attn.bias', 'h.1.crossattention.c_attn.bias', 'h.10.crossattention.c_proj.bias', 'h.1.crossattention.c_attn.weight', 'h.10.crossattention.q_attn.bias', 'h.7.crossattention.c_proj.weight', 'h.11.ln_cross_attn.weight', 'h.6.crossattention.c_proj.bias', 'h.0.crossattention.c_attn.bias', 'h.3.crossattention.c_attn.weight', 'h.6.crossattention.q_attn.bias', 'h.1.crossattention.c_proj.bias', 'h.2.crossattention.q_attn.weight', 'h.9.crossattention.q_attn.bias', 'h.5.crossattention.c_proj.bias', 'h.6.crossattention.c_proj.weight', 'h.11.crossattention.c_proj.bias', 'h.9.ln_cross_attn.bias', 'h.1.ln_cross_attn.bias', 'h.6.crossattention.q_attn.weight', 'h.10.crossattention.c_attn.weight', 'h.1.crossattention.c_proj.weight', 'h.8.crossattention.c_attn.weight', 'h.7.crossattention.q_attn.bias', 'h.4.crossattention.c_proj.bias', 'h.10.crossattention.q_attn.weight', 'h.10.crossattention.c_attn.bias', 'h.9.crossattention.c_proj.weight', 'h.0.crossattention.c_proj.bias', 'h.1.crossattention.q_attn.bias', 'h.11.crossattention.q_attn.weight', 'h.1.crossattention.q_attn.weight', 'h.6.ln_cross_attn.weight', 'h.7.ln_cross_attn.bias', 'h.3.ln_cross_attn.weight', 'h.9.ln_cross_attn.weight', 'h.3.crossattention.c_attn.bias', 'h.6.crossattention.c_attn.weight', 'h.8.crossattention.q_attn.weight', 'h.9.crossattention.c_proj.bias', 'h.6.crossattention.c_attn.bias', 'h.9.crossattention.q_attn.weight', 'h.8.ln_cross_attn.bias', 'h.7.ln_cross_attn.weight', 'h.2.crossattention.c_proj.weight', 'h.8.crossattention.q_attn.bias', 'h.7.crossattention.q_attn.weight', 'h.8.ln_cross_attn.weight', 'h.2.crossattention.c_proj.bias', 'h.2.ln_cross_attn.bias', 'h.5.ln_cross_attn.bias', 'h.0.ln_cross_attn.bias', 'h.3.crossattention.q_attn.weight', 'h.10.ln_cross_attn.bias', 'h.7.crossattention.c_proj.bias', 'h.6.ln_cross_attn.bias', 'h.5.crossattention.c_attn.bias', 'h.4.crossattention.c_proj.weight', 'h.11.crossattention.c_attn.weight', 'h.11.crossattention.q_attn.bias', 'h.1.ln_cross_attn.weight', 'h.4.crossattention.c_attn.weight', 'h.5.crossattention.c_attn.weight', 'h.7.crossattention.c_attn.bias', 'h.0.crossattention.q_attn.bias', 'h.0.ln_cross_attn.weight', 'h.5.crossattention.q_attn.bias', 'h.4.ln_cross_attn.bias', 'h.4.crossattention.q_attn.weight', 'h.4.crossattention.q_attn.bias', 'h.2.crossattention.c_attn.bias', 'h.8.crossattention.c_proj.bias', 'h.9.crossattention.c_attn.bias', 'h.0.crossattention.c_proj.weight', 'h.7.crossattention.c_attn.weight', 'h.5.crossattention.c_proj.weight', 'h.9.crossattention.c_attn.weight', 'h.11.crossattention.c_attn.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "source_lng = \"ja\"\n",
    "\n",
    "if source_lng == \"en\":\n",
    "    target_lng = \"ja\"\n",
    "    encoder = \"bert-base-uncased\"\n",
    "    decoder = \"rinna/japanese-gpt2-small\"\n",
    "else: \n",
    "    target_lng = \"en\"\n",
    "    encoder = \"cl-tohoku/bert-base-japanese-v3\"\n",
    "    decoder = \"gpt2\"\n",
    "\n",
    "model = EncoderDecoderModel.from_encoder_decoder_pretrained(\n",
    "    encoder, decoder, encoder_add_pooling_layer=False\n",
    ")\n",
    "model.cuda();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of parameters:  263,423,232 (1,004.9MB)\n",
      "Cross-attention parameters:   28,366,848 (  108.2MB)\n"
     ]
    }
   ],
   "source": [
    "def print_model_parameters():\n",
    "    t_pars, t_bytes = 0, 0\n",
    "    for p in model.parameters():\n",
    "        t_pars += p.nelement()\n",
    "        t_bytes += p.nelement() * p.element_size()\n",
    "\n",
    "    c_attn_pars, c_attn_bytes = 0, 0\n",
    "    for layer in model.decoder.transformer.h:\n",
    "        for p in layer.crossattention.parameters():\n",
    "            c_attn_pars += p.nelement()\n",
    "            c_attn_bytes += p.nelement() * p.element_size()\n",
    "        for p in layer.ln_cross_attn.parameters():\n",
    "            c_attn_pars += p.nelement()\n",
    "            c_attn_bytes += p.nelement() * p.element_size()\n",
    "\n",
    "    print(f\"Total number of parameters: {t_pars:12,} ({(t_bytes / 1024**2):7,.1f}MB)\")\n",
    "    print(f\"Cross-attention parameters: {c_attn_pars:12,} ({(c_attn_bytes / 1024**2):7,.1f}MB)\")\n",
    "\n",
    "print_model_parameters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_cross_attention_only(model):\n",
    "    for p in model.parameters():\n",
    "        p.requires_grad = False\n",
    "    for layer in model.decoder.transformer.h:\n",
    "        for p in layer.crossattention.parameters():\n",
    "            p.requires_grad = True\n",
    "        for p in layer.ln_cross_attn.parameters():\n",
    "            p.requires_grad = True\n",
    "# set_cross_attention_only(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder_tokenizer = AutoTokenizer.from_pretrained(encoder, use_fast=True)\n",
    "decoder_tokenizer = AutoTokenizer.from_pretrained(decoder, use_fast=True)\n",
    "if decoder_tokenizer.pad_token_id is None:\n",
    "    decoder_tokenizer.pad_token_id = decoder_tokenizer.eos_token_id\n",
    "\n",
    "model.config.decoder_start_token_id = decoder_tokenizer.bos_token_id\n",
    "model.config.eos_token_id = decoder_tokenizer.eos_token_id\n",
    "model.config.pad_token_id = decoder_tokenizer.eos_token_id\n",
    "\n",
    "# add EOS token at the end of each sentence\n",
    "decoder_tokenizer._tokenizer.post_processor = processors.TemplateProcessing(\n",
    "    single=\"$A \" + decoder_tokenizer.eos_token,\n",
    "    special_tokens=[(decoder_tokenizer.eos_token, decoder_tokenizer.eos_token_id)],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.dataset import EnJaDatasetMaker\n",
    "from transformers import DataCollatorForSeq2Seq\n",
    "\n",
    "dataset = EnJaDatasetMaker.load_dataset(\"ja-en-test-1\")\n",
    "train_data = dataset.select(range(100))\n",
    "valid_data = dataset.select(range(100, 150))\n",
    "\n",
    "data_collator = DataCollatorForSeq2Seq(encoder_tokenizer, model=model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "metric = evaluate.load(\"sacrebleu\")\n",
    "\n",
    "def compute_metrics(preds):\n",
    "    preds_ids, labels_ids = preds\n",
    "\n",
    "    labels_ids[labels_ids == -100] = decoder_tokenizer.eos_token_id\n",
    "    references = decoder_tokenizer.batch_decode(labels_ids, skip_special_tokens=True)\n",
    "    references = [[reference] for reference in references]\n",
    "\n",
    "    predictions = decoder_tokenizer.batch_decode(preds_ids, skip_special_tokens=True)\n",
    "\n",
    "    if target_lng == \"ja\":\n",
    "        bleu_output = metric.compute(\n",
    "            references=references, \n",
    "            predictions=predictions, \n",
    "            tokenize=\"ja-mecab\"\n",
    "        )\n",
    "    else:\n",
    "        bleu_output = metric.compute(\n",
    "            references=references, \n",
    "            predictions=predictions\n",
    "        )\n",
    "    return bleu_output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_LENGHT = 128\n",
    "def set_decoder_configuration(gc: GenerationConfig):\n",
    "    gc.no_repeat_ngram_size = 3\n",
    "    gc.length_penalty = 2.0\n",
    "    gc.num_beams = 3\n",
    "    #gen_config.max_new_tokens = MAX_LENGHT\n",
    "    gc.max_length = MAX_LENGHT * 2\n",
    "    gc.min_length = 0\n",
    "    gc.early_stopping = True\n",
    "    gc.pad_token_id = decoder_tokenizer.eos_token_id\n",
    "    gc.bos_token_id = decoder_tokenizer.bos_token_id\n",
    "    gc.eos_token_id = decoder_tokenizer.eos_token_id\n",
    "    return gc\n",
    "\n",
    "gen_config = GenerationConfig()\n",
    "gen_config = set_decoder_configuration(gen_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_args = Seq2SeqTrainingArguments(\n",
    "    report_to=\"wandb\",\n",
    "    run_name=\"testing-data-maker-1\",\n",
    "    num_train_epochs=10,\n",
    "\n",
    "    logging_strategy=\"steps\",\n",
    "    logging_steps=10,\n",
    "\n",
    "    evaluation_strategy=\"epoch\",\n",
    "\n",
    "    output_dir=\"./.ckp/\",\n",
    "    save_strategy=\"steps\",\n",
    "    save_steps=1000,\n",
    "    save_total_limit=4,\n",
    "\n",
    "    optim=\"adamw_torch\",\n",
    "    bf16=True,\n",
    "\n",
    "    per_device_train_batch_size=8,\n",
    "    gradient_accumulation_steps=1,\n",
    "    \n",
    "    group_by_length=True,\n",
    "    length_column_name=\"length\",\n",
    "\n",
    "    per_device_eval_batch_size=8,\n",
    "    predict_with_generate=True,\n",
    "    generation_config=gen_config,\n",
    "    # torch_compile=True,\n",
    "    # label_smoothing_factor=0,\n",
    "    # auto_find_batch_size=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = Seq2SeqTrainer(\n",
    "    model, \n",
    "    args=train_args,\n",
    "    data_collator=data_collator,\n",
    "    train_dataset=train_data, \n",
    "    eval_dataset=valid_data, \n",
    "    compute_metrics=compute_metrics\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mdavidboening\u001b[0m (\u001b[33mdandd\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.15.8"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>c:\\src\\nlp-project\\wandb\\run-20230812_185712-x04kukle</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/dandd/huggingface/runs/x04kukle' target=\"_blank\">testing-data-maker-1</a></strong> to <a href='https://wandb.ai/dandd/huggingface' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/dandd/huggingface' target=\"_blank\">https://wandb.ai/dandd/huggingface</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/dandd/huggingface/runs/x04kukle' target=\"_blank\">https://wandb.ai/dandd/huggingface/runs/x04kukle</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "091a5a26778848ecb3b5fdbda31189e7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/650 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\src\\nlp-project\\venv\\lib\\site-packages\\transformers\\models\\encoder_decoder\\modeling_encoder_decoder.py:642: FutureWarning: Version v4.12.0 introduces a better way to train encoder-decoder models by computing the loss inside the encoder-decoder framework rather than in the decoder itself. You may observe training discrepancies if fine-tuning a model trained with versions anterior to 4.12.0. The decoder_input_ids are now created based on the labels, no need to pass them yourself anymore.\n",
      "  warnings.warn(DEPRECATION_WARNING, FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 4.1641, 'learning_rate': 4.923076923076924e-05, 'epoch': 0.77}\n",
      "{'loss': 3.0033, 'learning_rate': 4.846153846153846e-05, 'epoch': 1.54}\n",
      "{'loss': 2.3679, 'learning_rate': 4.76923076923077e-05, 'epoch': 2.31}\n",
      "{'loss': 2.0273, 'learning_rate': 4.692307692307693e-05, 'epoch': 3.08}\n",
      "{'loss': 1.626, 'learning_rate': 4.615384615384616e-05, 'epoch': 3.85}\n",
      "{'loss': 1.3038, 'learning_rate': 4.538461538461539e-05, 'epoch': 4.62}\n",
      "{'loss': 1.183, 'learning_rate': 4.461538461538462e-05, 'epoch': 5.38}\n",
      "{'loss': 0.9856, 'learning_rate': 4.384615384615385e-05, 'epoch': 6.15}\n",
      "{'loss': 0.8227, 'learning_rate': 4.3076923076923084e-05, 'epoch': 6.92}\n",
      "{'loss': 0.7118, 'learning_rate': 4.230769230769231e-05, 'epoch': 7.69}\n",
      "{'loss': 0.6145, 'learning_rate': 4.1538461538461544e-05, 'epoch': 8.46}\n",
      "{'loss': 0.6536, 'learning_rate': 4.0769230769230773e-05, 'epoch': 9.23}\n",
      "{'loss': 0.531, 'learning_rate': 4e-05, 'epoch': 10.0}\n",
      "{'loss': 0.415, 'learning_rate': 3.923076923076923e-05, 'epoch': 10.77}\n",
      "{'loss': 0.4189, 'learning_rate': 3.846153846153846e-05, 'epoch': 11.54}\n",
      "{'loss': 0.5109, 'learning_rate': 3.769230769230769e-05, 'epoch': 12.31}\n",
      "{'loss': 0.3262, 'learning_rate': 3.692307692307693e-05, 'epoch': 13.08}\n",
      "{'loss': 0.3185, 'learning_rate': 3.615384615384615e-05, 'epoch': 13.85}\n",
      "{'loss': 0.2355, 'learning_rate': 3.538461538461539e-05, 'epoch': 14.62}\n",
      "{'loss': 0.2028, 'learning_rate': 3.461538461538462e-05, 'epoch': 15.38}\n",
      "{'loss': 0.2546, 'learning_rate': 3.384615384615385e-05, 'epoch': 16.15}\n",
      "{'loss': 0.2929, 'learning_rate': 3.307692307692308e-05, 'epoch': 16.92}\n",
      "{'loss': 0.3456, 'learning_rate': 3.230769230769231e-05, 'epoch': 17.69}\n",
      "{'loss': 0.2769, 'learning_rate': 3.153846153846154e-05, 'epoch': 18.46}\n",
      "{'loss': 0.2277, 'learning_rate': 3.0769230769230774e-05, 'epoch': 19.23}\n",
      "{'loss': 0.232, 'learning_rate': 3e-05, 'epoch': 20.0}\n",
      "{'loss': 0.2214, 'learning_rate': 2.9230769230769234e-05, 'epoch': 20.77}\n",
      "{'loss': 0.228, 'learning_rate': 2.846153846153846e-05, 'epoch': 21.54}\n",
      "{'loss': 0.1893, 'learning_rate': 2.7692307692307694e-05, 'epoch': 22.31}\n",
      "{'loss': 0.153, 'learning_rate': 2.6923076923076923e-05, 'epoch': 23.08}\n",
      "{'loss': 0.2333, 'learning_rate': 2.6153846153846157e-05, 'epoch': 23.85}\n",
      "{'loss': 0.1752, 'learning_rate': 2.5384615384615383e-05, 'epoch': 24.62}\n",
      "{'loss': 0.1654, 'learning_rate': 2.461538461538462e-05, 'epoch': 25.38}\n",
      "{'loss': 0.139, 'learning_rate': 2.384615384615385e-05, 'epoch': 26.15}\n",
      "{'loss': 0.1331, 'learning_rate': 2.307692307692308e-05, 'epoch': 26.92}\n",
      "{'loss': 0.2117, 'learning_rate': 2.230769230769231e-05, 'epoch': 27.69}\n",
      "{'loss': 0.1318, 'learning_rate': 2.1538461538461542e-05, 'epoch': 28.46}\n",
      "{'loss': 0.12, 'learning_rate': 2.0769230769230772e-05, 'epoch': 29.23}\n",
      "{'loss': 0.1222, 'learning_rate': 2e-05, 'epoch': 30.0}\n",
      "{'loss': 0.1275, 'learning_rate': 1.923076923076923e-05, 'epoch': 30.77}\n",
      "{'loss': 0.1549, 'learning_rate': 1.8461538461538465e-05, 'epoch': 31.54}\n",
      "{'loss': 0.0938, 'learning_rate': 1.7692307692307694e-05, 'epoch': 32.31}\n",
      "{'loss': 0.118, 'learning_rate': 1.6923076923076924e-05, 'epoch': 33.08}\n",
      "{'loss': 0.0808, 'learning_rate': 1.6153846153846154e-05, 'epoch': 33.85}\n",
      "{'loss': 0.17, 'learning_rate': 1.5384615384615387e-05, 'epoch': 34.62}\n",
      "{'loss': 0.1453, 'learning_rate': 1.4615384615384617e-05, 'epoch': 35.38}\n",
      "{'loss': 0.0623, 'learning_rate': 1.3846153846153847e-05, 'epoch': 36.15}\n",
      "{'loss': 0.214, 'learning_rate': 1.3076923076923078e-05, 'epoch': 36.92}\n",
      "{'loss': 0.0804, 'learning_rate': 1.230769230769231e-05, 'epoch': 37.69}\n",
      "{'loss': 0.0782, 'learning_rate': 1.153846153846154e-05, 'epoch': 38.46}\n",
      "{'loss': 0.0919, 'learning_rate': 1.0769230769230771e-05, 'epoch': 39.23}\n",
      "{'loss': 0.0905, 'learning_rate': 1e-05, 'epoch': 40.0}\n",
      "{'loss': 0.0727, 'learning_rate': 9.230769230769232e-06, 'epoch': 40.77}\n",
      "{'loss': 0.0444, 'learning_rate': 8.461538461538462e-06, 'epoch': 41.54}\n",
      "{'loss': 0.107, 'learning_rate': 7.692307692307694e-06, 'epoch': 42.31}\n",
      "{'loss': 0.0738, 'learning_rate': 6.923076923076923e-06, 'epoch': 43.08}\n",
      "{'loss': 0.1497, 'learning_rate': 6.153846153846155e-06, 'epoch': 43.85}\n",
      "{'loss': 0.0955, 'learning_rate': 5.3846153846153855e-06, 'epoch': 44.62}\n",
      "{'loss': 0.0802, 'learning_rate': 4.615384615384616e-06, 'epoch': 45.38}\n",
      "{'loss': 0.1015, 'learning_rate': 3.846153846153847e-06, 'epoch': 46.15}\n",
      "{'loss': 0.0978, 'learning_rate': 3.0769230769230774e-06, 'epoch': 46.92}\n",
      "{'loss': 0.0871, 'learning_rate': 2.307692307692308e-06, 'epoch': 47.69}\n",
      "{'loss': 0.1195, 'learning_rate': 1.5384615384615387e-06, 'epoch': 48.46}\n",
      "{'loss': 0.1599, 'learning_rate': 7.692307692307694e-07, 'epoch': 49.23}\n",
      "{'loss': 0.0533, 'learning_rate': 0.0, 'epoch': 50.0}\n",
      "{'train_runtime': 242.7068, 'train_samples_per_second': 20.601, 'train_steps_per_second': 2.678, 'train_loss': 0.44654285747271316, 'epoch': 50.0}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=650, training_loss=0.44654285747271316, metrics={'train_runtime': 242.7068, 'train_samples_per_second': 20.601, 'train_steps_per_second': 2.678, 'train_loss': 0.44654285747271316, 'epoch': 50.0})"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.train()\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "99844ba7ec84436197148cad6e30365f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/13 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a79f4c365a4048fda8ac0d3846fb8f6a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/7 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: {'score': 98.90981656809547, 'counts': [740, 641, 542, 443], 'totals': [748, 648, 548, 448], 'precisions': [98.93048128342247, 98.91975308641975, 98.9051094890511, 98.88392857142857], 'bp': 1.0, 'sys_len': 748, 'ref_len': 740}\n",
      "Valid: {'score': 1.6850151200126198, 'counts': [62, 7, 2, 1], 'totals': [372, 322, 272, 222], 'precisions': [16.666666666666668, 2.1739130434782608, 0.7352941176470589, 0.45045045045045046], 'bp': 0.905324020561496, 'sys_len': 372, 'ref_len': 409}\n"
     ]
    }
   ],
   "source": [
    "model.cuda()\n",
    "model.eval()\n",
    "train_out = trainer.predict(train_data)\n",
    "valid_out = trainer.predict(valid_data)\n",
    "\n",
    "print(\"Train:\", compute_metrics((train_out.predictions, train_data[\"labels\"])))\n",
    "print(\"Valid:\", compute_metrics((valid_out.predictions, valid_data[\"labels\"])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_decode = decoder_tokenizer.batch_decode(train_out.predictions, skip_special_tokens=True)\n",
    "valid_decode = decoder_tokenizer.batch_decode(valid_out.predictions, skip_special_tokens=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentence #0 [id=81]\n",
      "\tOriginal:  花を入れるものには何本の花が入っていますか。\n",
      "\tTarget:    how many flowers are there in the vase ?\n",
      "\tGenerated: how many flowers are there in the vase?\n",
      "\n",
      "Sentence #1 [id=14]\n",
      "\tOriginal:  私たちはローマで楽しく過ごしてます。\n",
      "\tTarget:    we are having a nice time in rome .\n",
      "\tGenerated: we are having a nice time in rome.\n",
      "\n",
      "Sentence #2 [id=3]\n",
      "\tOriginal:  彼女はとても美しい。その上、とても賢い。\n",
      "\tTarget:    she is very beautiful , and what is more , very wise .\n",
      "\tGenerated: she is very beautiful, and what is more, very wise.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def print_pairs(dataset, generation, sample=5):\n",
    "    assert len(dataset) == len(generation), \"Invalid combination!\"\n",
    "\n",
    "    sample_ids = random.sample(range(len(dataset)), sample)\n",
    "    for i, sid in enumerate(sample_ids):\n",
    "        print(f\"Sentence #{i} [id={sid}]\")\n",
    "        print(\n",
    "            f\"\\tOriginal:  {dataset['source'][sid]}\\n\"\n",
    "            f\"\\tTarget:    {dataset['target'][sid]}\\n\"\n",
    "            f\"\\tGenerated: {generation[sid]}\\n\"\n",
    "        )\n",
    "    return\n",
    "\n",
    "print_pairs(train_data, train_decode, sample=3)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "NLP",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
