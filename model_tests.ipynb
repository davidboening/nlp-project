{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import os\n",
    "os.environ[\"HF_HOME\"] = r\"./.cache\"\n",
    "\n",
    "from transformers import EncoderDecoderModel, AutoTokenizer, GenerationConfig, Seq2SeqTrainer, Seq2SeqTrainingArguments\n",
    "from tokenizers import processors\n",
    "import evaluate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Encoders\n",
    "    - BERT_JA : `cl-tohoku/bert-base-japanese-v3`\n",
    "    - BERT_EN : `bert-base-uncased`, `prajjwal1/bert-tiny`\n",
    "- Decorders\n",
    "    - GPT_JA : `rinna/japanese-gpt2-xsmall`\n",
    "    - GPT_EN : `gpt2`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of GPT2LMHeadModel were not initialized from the model checkpoint at gpt2 and are newly initialized: ['h.10.crossattention.c_proj.bias', 'h.10.ln_cross_attn.weight', 'h.10.ln_cross_attn.bias', 'h.0.crossattention.c_attn.weight', 'h.9.ln_cross_attn.bias', 'h.8.crossattention.c_attn.weight', 'h.4.crossattention.c_proj.bias', 'h.2.crossattention.c_attn.bias', 'h.4.crossattention.q_attn.bias', 'h.2.crossattention.c_attn.weight', 'h.9.crossattention.q_attn.weight', 'h.4.crossattention.c_attn.weight', 'h.6.crossattention.c_attn.weight', 'h.7.ln_cross_attn.bias', 'h.1.crossattention.c_proj.bias', 'h.5.crossattention.c_proj.weight', 'h.0.crossattention.q_attn.bias', 'h.11.crossattention.c_proj.weight', 'h.10.crossattention.c_proj.weight', 'h.0.ln_cross_attn.weight', 'h.11.crossattention.c_attn.bias', 'h.9.crossattention.q_attn.bias', 'h.10.crossattention.q_attn.weight', 'h.3.ln_cross_attn.weight', 'h.4.crossattention.c_proj.weight', 'h.7.crossattention.c_proj.weight', 'h.7.ln_cross_attn.weight', 'h.8.crossattention.c_proj.weight', 'h.1.crossattention.c_proj.weight', 'h.1.crossattention.c_attn.weight', 'h.2.ln_cross_attn.bias', 'h.9.crossattention.c_proj.bias', 'h.7.crossattention.c_attn.weight', 'h.2.crossattention.c_proj.weight', 'h.6.crossattention.c_attn.bias', 'h.1.ln_cross_attn.weight', 'h.4.crossattention.c_attn.bias', 'h.3.crossattention.c_proj.bias', 'h.0.crossattention.c_proj.bias', 'h.5.crossattention.c_attn.bias', 'h.10.crossattention.q_attn.bias', 'h.6.ln_cross_attn.bias', 'h.8.crossattention.q_attn.weight', 'h.2.crossattention.q_attn.bias', 'h.3.crossattention.c_attn.bias', 'h.4.crossattention.q_attn.weight', 'h.0.crossattention.q_attn.weight', 'h.11.ln_cross_attn.bias', 'h.3.crossattention.q_attn.bias', 'h.11.crossattention.c_proj.bias', 'h.5.crossattention.c_proj.bias', 'h.0.crossattention.c_proj.weight', 'h.0.ln_cross_attn.bias', 'h.9.ln_cross_attn.weight', 'h.6.ln_cross_attn.weight', 'h.6.crossattention.q_attn.weight', 'h.1.crossattention.q_attn.bias', 'h.9.crossattention.c_proj.weight', 'h.0.crossattention.c_attn.bias', 'h.11.ln_cross_attn.weight', 'h.11.crossattention.c_attn.weight', 'h.8.crossattention.c_proj.bias', 'h.5.ln_cross_attn.weight', 'h.2.crossattention.c_proj.bias', 'h.7.crossattention.c_proj.bias', 'h.3.crossattention.c_attn.weight', 'h.5.crossattention.q_attn.bias', 'h.3.crossattention.c_proj.weight', 'h.5.crossattention.c_attn.weight', 'h.10.crossattention.c_attn.bias', 'h.5.crossattention.q_attn.weight', 'h.6.crossattention.c_proj.bias', 'h.9.crossattention.c_attn.bias', 'h.8.ln_cross_attn.weight', 'h.1.crossattention.c_attn.bias', 'h.4.ln_cross_attn.bias', 'h.7.crossattention.q_attn.bias', 'h.6.crossattention.c_proj.weight', 'h.8.crossattention.q_attn.bias', 'h.3.crossattention.q_attn.weight', 'h.1.crossattention.q_attn.weight', 'h.4.ln_cross_attn.weight', 'h.6.crossattention.q_attn.bias', 'h.3.ln_cross_attn.bias', 'h.5.ln_cross_attn.bias', 'h.10.crossattention.c_attn.weight', 'h.8.ln_cross_attn.bias', 'h.2.ln_cross_attn.weight', 'h.9.crossattention.c_attn.weight', 'h.11.crossattention.q_attn.weight', 'h.7.crossattention.c_attn.bias', 'h.8.crossattention.c_attn.bias', 'h.1.ln_cross_attn.bias', 'h.2.crossattention.q_attn.weight', 'h.11.crossattention.q_attn.bias', 'h.7.crossattention.q_attn.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "source_lng = \"ja\"\n",
    "\n",
    "if source_lng == \"en\":\n",
    "    target_lng = \"ja\"\n",
    "    encoder = \"bert-base-uncased\"\n",
    "    decoder = \"rinna/japanese-gpt2-small\"\n",
    "else: \n",
    "    target_lng = \"en\"\n",
    "    encoder = \"cl-tohoku/bert-base-japanese-v3\"\n",
    "    decoder = \"gpt2\"\n",
    "\n",
    "model = EncoderDecoderModel.from_encoder_decoder_pretrained(\n",
    "    encoder, decoder, encoder_add_pooling_layer=False\n",
    ")\n",
    "model.cuda();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of parameters:  263,423,232 (1,004.9MB)\n",
      "Cross-attention parameters:   28,366,848 (  108.2MB)\n"
     ]
    }
   ],
   "source": [
    "def print_model_parameters():\n",
    "    t_pars, t_bytes = 0, 0\n",
    "    for p in model.parameters():\n",
    "        t_pars += p.nelement()\n",
    "        t_bytes += p.nelement() * p.element_size()\n",
    "\n",
    "    c_attn_pars, c_attn_bytes = 0, 0\n",
    "    for layer in model.decoder.transformer.h:\n",
    "        for p in layer.crossattention.parameters():\n",
    "            c_attn_pars += p.nelement()\n",
    "            c_attn_bytes += p.nelement() * p.element_size()\n",
    "        for p in layer.ln_cross_attn.parameters():\n",
    "            c_attn_pars += p.nelement()\n",
    "            c_attn_bytes += p.nelement() * p.element_size()\n",
    "\n",
    "    print(f\"Total number of parameters: {t_pars:12,} ({(t_bytes / 1024**2):7,.1f}MB)\")\n",
    "    print(f\"Cross-attention parameters: {c_attn_pars:12,} ({(c_attn_bytes / 1024**2):7,.1f}MB)\")\n",
    "\n",
    "print_model_parameters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_cross_attention_only(model):\n",
    "    for p in model.parameters():\n",
    "        p.requires_grad = False\n",
    "    for layer in model.decoder.transformer.h:\n",
    "        for p in layer.crossattention.parameters():\n",
    "            p.requires_grad = True\n",
    "        for p in layer.ln_cross_attn.parameters():\n",
    "            p.requires_grad = True\n",
    "# set_cross_attention_only(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder_tokenizer = AutoTokenizer.from_pretrained(encoder, use_fast=True)\n",
    "decoder_tokenizer = AutoTokenizer.from_pretrained(decoder, use_fast=True)\n",
    "if decoder_tokenizer.pad_token_id is None:\n",
    "    decoder_tokenizer.pad_token_id = decoder_tokenizer.eos_token_id\n",
    "\n",
    "model.config.decoder_start_token_id = decoder_tokenizer.bos_token_id\n",
    "model.config.eos_token_id = decoder_tokenizer.eos_token_id\n",
    "model.config.pad_token_id = decoder_tokenizer.eos_token_id\n",
    "\n",
    "# add EOS token at the end of each sentence\n",
    "decoder_tokenizer._tokenizer.post_processor = processors.TemplateProcessing(\n",
    "    single=\"$A \" + decoder_tokenizer.eos_token,\n",
    "    special_tokens=[(decoder_tokenizer.eos_token, decoder_tokenizer.eos_token_id)],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.dataset import EnJaDatasetMaker\n",
    "from transformers import DataCollatorForSeq2Seq\n",
    "\n",
    "dataset = EnJaDatasetMaker.load_dataset(\"ja-en-test-1\")\n",
    "train_data = dataset.select(range(100))\n",
    "valid_data = dataset.select(range(100, 150))\n",
    "\n",
    "data_collator = DataCollatorForSeq2Seq(encoder_tokenizer, model=model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "metric = evaluate.load(\"sacrebleu\")\n",
    "\n",
    "def compute_metrics(preds):\n",
    "    preds_ids, labels_ids = preds\n",
    "\n",
    "    labels_ids[labels_ids == -100] = decoder_tokenizer.eos_token_id\n",
    "    references = decoder_tokenizer.batch_decode(labels_ids, skip_special_tokens=True)\n",
    "    references = [[reference] for reference in references]\n",
    "\n",
    "    predictions = decoder_tokenizer.batch_decode(preds_ids, skip_special_tokens=True)\n",
    "\n",
    "    if target_lng == \"ja\":\n",
    "        bleu_output = metric.compute(\n",
    "            references=references, \n",
    "            predictions=predictions, \n",
    "            tokenize=\"ja-mecab\"\n",
    "        )\n",
    "    else:\n",
    "        bleu_output = metric.compute(\n",
    "            references=references, \n",
    "            predictions=predictions\n",
    "        )\n",
    "    return bleu_output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_LENGHT = 128\n",
    "def set_decoder_configuration(gc: GenerationConfig):\n",
    "    gc.no_repeat_ngram_size = 3\n",
    "    gc.length_penalty = 2.0\n",
    "    gc.num_beams = 3\n",
    "    #gen_config.max_new_tokens = MAX_LENGHT\n",
    "    gc.max_length = MAX_LENGHT * 2\n",
    "    gc.min_length = 0\n",
    "    gc.early_stopping = True\n",
    "    gc.pad_token_id = decoder_tokenizer.eos_token_id\n",
    "    gc.bos_token_id = decoder_tokenizer.bos_token_id\n",
    "    gc.eos_token_id = decoder_tokenizer.eos_token_id\n",
    "    return gc\n",
    "\n",
    "gen_config = GenerationConfig()\n",
    "gen_config = set_decoder_configuration(gen_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_args = Seq2SeqTrainingArguments(\n",
    "    report_to=\"wandb\",\n",
    "    run_name=\"testing-data-maker-1\",\n",
    "    num_train_epochs=5,\n",
    "\n",
    "    logging_strategy=\"steps\",\n",
    "    logging_steps=10,\n",
    "\n",
    "    evaluation_strategy=\"epoch\",\n",
    "\n",
    "    output_dir=\"./.ckp/\",\n",
    "    save_strategy=\"steps\",\n",
    "    save_steps=1000,\n",
    "    save_total_limit=4,\n",
    "\n",
    "    optim=\"adamw_torch\",\n",
    "    bf16=True,\n",
    "\n",
    "    per_device_train_batch_size=8,\n",
    "    gradient_accumulation_steps=1,\n",
    "    \n",
    "    group_by_length=True,\n",
    "    length_column_name=\"length\",\n",
    "\n",
    "    per_device_eval_batch_size=8,\n",
    "    predict_with_generate=True,\n",
    "    generation_config=gen_config,\n",
    "    # torch_compile=True,\n",
    "    # label_smoothing_factor=0,\n",
    "    # auto_find_batch_size=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = Seq2SeqTrainer(\n",
    "    model, \n",
    "    args=train_args,\n",
    "    data_collator=data_collator,\n",
    "    train_dataset=train_data.remove_columns(\"\"), \n",
    "    eval_dataset=valid_data, \n",
    "    compute_metrics=compute_metrics\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['あまり他人には頼ってはいけない。',\n",
       " '私は今年は成績が悪かった。',\n",
       " '今日は我々は野宿しないといけない。',\n",
       " '彼女はとても美しい。その上、とても賢い。',\n",
       " '静かに歩けないのか。',\n",
       " 'もう一度送ってくれませんか。',\n",
       " 'タクシーが到着した。',\n",
       " 'あなたのためならどんなことでもするよ。',\n",
       " '通りを歩いていたら、財布を見つけた。',\n",
       " '他人には親切であれ。',\n",
       " '私と行けば一番いいんだろう。',\n",
       " 'あの男は目つきが悪い。',\n",
       " 'トムは歩いて学校へ通っている。',\n",
       " '彼の言ったことはいい意見だ。',\n",
       " '私たちはローマで楽しく過ごしてます。',\n",
       " '学校まで一緒に歩いてくれませんか。',\n",
       " '残念ながらあなたを助けることは出来ません。',\n",
       " 'お釣りが違いますよ。',\n",
       " '私はそこへ１度行ったことがある。',\n",
       " '彼女は決して馬鹿ではない。',\n",
       " '彼が歌っているのが、聞こえますか。',\n",
       " '私が忘れたら注意してください。',\n",
       " '私のことはおいておいてくれ！',\n",
       " 'あなたに家にいてもらいたい。',\n",
       " '僕があなたの仕事を次にしよう。',\n",
       " '子供でも世の中の事を理解する必要がある。',\n",
       " '彼女は私に「おはよう」とさえ言わなかった。',\n",
       " 'この時計は水に強いです。',\n",
       " '彼は幸福な生活を送った。',\n",
       " 'その仕事は私の健康にとって負担だ。',\n",
       " 'あなたの努力はもうすぐ結果が出るだろう。',\n",
       " 'これはなんと面白い本でしょう。',\n",
       " '彼は私の兄よりも年上に見えます。',\n",
       " '彼は彼女のたよりを待ち望んでいる。',\n",
       " '彼女のお母さんは前の週の木曜日から病気です。',\n",
       " '僕は彼女の歌のピアノを弾いた。',\n",
       " 'もうベッドにつかなくてはなりません。',\n",
       " '英語を書くときは、彼はしばしば辞書を調べる。',\n",
       " '行ってしまえ！',\n",
       " '数学は難しい科目だ。',\n",
       " '１時間経過すれば戻ってきます。',\n",
       " '彼が言ったことは正しくないとわかった。',\n",
       " 'その小説を作った人は誰ですか。',\n",
       " '両親は私が外国の学校で勉強をすることに反対した。',\n",
       " '彼女はその手紙を日本語からフランス語の翻訳した。',\n",
       " '私はいつものように早く起きた。',\n",
       " '私を見なさい。',\n",
       " 'どの電車に乗るのですか。',\n",
       " '彼は音楽会が終わるまでには到着しなかった。',\n",
       " 'アリスはその犬を見なかった。',\n",
       " '先生は２時間もしゃべり続けた。',\n",
       " '私はその本を座るところの右においている。',\n",
       " '彼と一緒だと安心するの。',\n",
       " '私はお茶が好きです。',\n",
       " '私は昨日夜遅い時間まで起きていた。',\n",
       " 'それで、その金はどこから出るんだね？',\n",
       " 'こんにちは！ここで働かれているんですか。',\n",
       " 'そこで何をしていたのか。',\n",
       " 'どんな方法をしてもダメだった。',\n",
       " '彼は甘いものならなんでも好きです。',\n",
       " '彼は私たちのクラスを担当する人だ。',\n",
       " '箱の中にりんごがどれだけかありますか。',\n",
       " '私はどうでもいい。',\n",
       " 'ショーは後どれくらいで始まりますか。',\n",
       " '私の手が彼女の手に触れた。',\n",
       " '彼女はひどい寒がりだ。',\n",
       " 'あの人の前では頭が上がらない。',\n",
       " '彼女はどこへ行ってしまったのかな。',\n",
       " 'そんなことをするとはなんて私はばかだったのだ。',\n",
       " '彼は２時間後に戻ってきた。',\n",
       " '彼は、このようなことがうまいのです。',\n",
       " '雪さえ降らなければね！',\n",
       " 'この本です。',\n",
       " '彼の考えをどう思いますか。',\n",
       " '私の家は炎に包まれました。',\n",
       " '彼女はここにいて幸せそうに見えます。',\n",
       " '私はその問題を自分で解決するができます。',\n",
       " '何とかしてください。',\n",
       " '私は歌手になりたい。',\n",
       " '彼と接触してはいけない。',\n",
       " '彼は私たちに英語を教えてくれる。',\n",
       " '花を入れるものには何本の花が入っていますか。',\n",
       " '朝食をもう済ませましたか。',\n",
       " '私について部屋に入りなさい。',\n",
       " '列車はすぐに来ると思います。',\n",
       " '彼は私の兄と同じくらいの背の高さです。',\n",
       " '３日連続して雨が降った。',\n",
       " 'その男は元気いっぱい、休暇から戻ってきた。',\n",
       " '彼はすぐに帰ってきますか。',\n",
       " '彼はその町で道に迷った。',\n",
       " 'おかげさまで助かりました。',\n",
       " 'この辞書は高い。',\n",
       " 'すみません、お役に立てなくて。',\n",
       " '私はその時、家を出るところだった。',\n",
       " '彼ら二人はよく肌が合う。',\n",
       " '彼女と話をするのはうんざりだ。',\n",
       " 'ここでうるさくしてはならない。',\n",
       " '彼はまさにロンドンへ出発しようとしている。',\n",
       " 'これはとても味が穏やかなコーヒーだ。',\n",
       " '多くの人々がそのコンサートに来た。']"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data[\"source\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "all the input arrays must have same number of dimensions, but the array at index 0 has 2 dimension(s) and the array at index 1 has 1 dimension(s)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[14], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m data_collator(train_data)\n",
      "File \u001b[1;32mc:\\src\\nlp-project\\venv\\lib\\site-packages\\transformers\\data\\data_collator.py:582\u001b[0m, in \u001b[0;36mDataCollatorForSeq2Seq.__call__\u001b[1;34m(self, features, return_tensors)\u001b[0m\n\u001b[0;32m    578\u001b[0m     feature[\u001b[39m\"\u001b[39m\u001b[39mlabels\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m (\n\u001b[0;32m    579\u001b[0m         feature[\u001b[39m\"\u001b[39m\u001b[39mlabels\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m+\u001b[39m remainder \u001b[39mif\u001b[39;00m padding_side \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mright\u001b[39m\u001b[39m\"\u001b[39m \u001b[39melse\u001b[39;00m remainder \u001b[39m+\u001b[39m feature[\u001b[39m\"\u001b[39m\u001b[39mlabels\u001b[39m\u001b[39m\"\u001b[39m]\n\u001b[0;32m    580\u001b[0m     )\n\u001b[0;32m    581\u001b[0m \u001b[39melif\u001b[39;00m padding_side \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mright\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[1;32m--> 582\u001b[0m     feature[\u001b[39m\"\u001b[39m\u001b[39mlabels\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39;49mconcatenate([feature[\u001b[39m\"\u001b[39;49m\u001b[39mlabels\u001b[39;49m\u001b[39m\"\u001b[39;49m], remainder])\u001b[39m.\u001b[39mastype(np\u001b[39m.\u001b[39mint64)\n\u001b[0;32m    583\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    584\u001b[0m     feature[\u001b[39m\"\u001b[39m\u001b[39mlabels\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mconcatenate([remainder, feature[\u001b[39m\"\u001b[39m\u001b[39mlabels\u001b[39m\u001b[39m\"\u001b[39m]])\u001b[39m.\u001b[39mastype(np\u001b[39m.\u001b[39mint64)\n",
      "\u001b[1;31mValueError\u001b[0m: all the input arrays must have same number of dimensions, but the array at index 0 has 2 dimension(s) and the array at index 1 has 1 dimension(s)"
     ]
    }
   ],
   "source": [
    "data_collator(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mdavidboening\u001b[0m (\u001b[33mdandd\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.15.8"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>c:\\src\\nlp-project\\wandb\\run-20230812_183716-46yhrw32</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/dandd/huggingface/runs/46yhrw32' target=\"_blank\">testing-data-maker-1</a></strong> to <a href='https://wandb.ai/dandd/huggingface' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/dandd/huggingface' target=\"_blank\">https://wandb.ai/dandd/huggingface</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/dandd/huggingface/runs/46yhrw32' target=\"_blank\">https://wandb.ai/dandd/huggingface/runs/46yhrw32</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7c521533ddaa4813b8c6655a32522116",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/65 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "ValueError",
     "evalue": "all the input arrays must have same number of dimensions, but the array at index 0 has 2 dimension(s) and the array at index 1 has 1 dimension(s)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[11], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m model\u001b[39m.\u001b[39mtrain()\n\u001b[1;32m----> 2\u001b[0m trainer\u001b[39m.\u001b[39;49mtrain()\n",
      "File \u001b[1;32mc:\\src\\nlp-project\\venv\\lib\\site-packages\\transformers\\trainer.py:1539\u001b[0m, in \u001b[0;36mTrainer.train\u001b[1;34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001b[0m\n\u001b[0;32m   1534\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmodel_wrapped \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmodel\n\u001b[0;32m   1536\u001b[0m inner_training_loop \u001b[39m=\u001b[39m find_executable_batch_size(\n\u001b[0;32m   1537\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_inner_training_loop, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_train_batch_size, args\u001b[39m.\u001b[39mauto_find_batch_size\n\u001b[0;32m   1538\u001b[0m )\n\u001b[1;32m-> 1539\u001b[0m \u001b[39mreturn\u001b[39;00m inner_training_loop(\n\u001b[0;32m   1540\u001b[0m     args\u001b[39m=\u001b[39;49margs,\n\u001b[0;32m   1541\u001b[0m     resume_from_checkpoint\u001b[39m=\u001b[39;49mresume_from_checkpoint,\n\u001b[0;32m   1542\u001b[0m     trial\u001b[39m=\u001b[39;49mtrial,\n\u001b[0;32m   1543\u001b[0m     ignore_keys_for_eval\u001b[39m=\u001b[39;49mignore_keys_for_eval,\n\u001b[0;32m   1544\u001b[0m )\n",
      "File \u001b[1;32mc:\\src\\nlp-project\\venv\\lib\\site-packages\\transformers\\trainer.py:1787\u001b[0m, in \u001b[0;36mTrainer._inner_training_loop\u001b[1;34m(self, batch_size, args, resume_from_checkpoint, trial, ignore_keys_for_eval)\u001b[0m\n\u001b[0;32m   1784\u001b[0m     rng_to_sync \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n\u001b[0;32m   1786\u001b[0m step \u001b[39m=\u001b[39m \u001b[39m-\u001b[39m\u001b[39m1\u001b[39m\n\u001b[1;32m-> 1787\u001b[0m \u001b[39mfor\u001b[39;00m step, inputs \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(epoch_iterator):\n\u001b[0;32m   1788\u001b[0m     total_batched_samples \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[0;32m   1789\u001b[0m     \u001b[39mif\u001b[39;00m rng_to_sync:\n",
      "File \u001b[1;32mc:\\src\\nlp-project\\venv\\lib\\site-packages\\accelerate\\data_loader.py:384\u001b[0m, in \u001b[0;36mDataLoaderShard.__iter__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    382\u001b[0m \u001b[39m# We iterate one batch ahead to check when we are at the end\u001b[39;00m\n\u001b[0;32m    383\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 384\u001b[0m     current_batch \u001b[39m=\u001b[39m \u001b[39mnext\u001b[39;49m(dataloader_iter)\n\u001b[0;32m    385\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mStopIteration\u001b[39;00m:\n\u001b[0;32m    386\u001b[0m     \u001b[39myield\u001b[39;00m\n",
      "File \u001b[1;32mc:\\src\\nlp-project\\venv\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:633\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    630\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_sampler_iter \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    631\u001b[0m     \u001b[39m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[0;32m    632\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_reset()  \u001b[39m# type: ignore[call-arg]\u001b[39;00m\n\u001b[1;32m--> 633\u001b[0m data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_next_data()\n\u001b[0;32m    634\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_yielded \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[0;32m    635\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_dataset_kind \u001b[39m==\u001b[39m _DatasetKind\u001b[39m.\u001b[39mIterable \u001b[39mand\u001b[39;00m \\\n\u001b[0;32m    636\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_IterableDataset_len_called \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m \\\n\u001b[0;32m    637\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_yielded \u001b[39m>\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[1;32mc:\\src\\nlp-project\\venv\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:677\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    675\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_next_data\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[0;32m    676\u001b[0m     index \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_next_index()  \u001b[39m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m--> 677\u001b[0m     data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_dataset_fetcher\u001b[39m.\u001b[39;49mfetch(index)  \u001b[39m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m    678\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_pin_memory:\n\u001b[0;32m    679\u001b[0m         data \u001b[39m=\u001b[39m _utils\u001b[39m.\u001b[39mpin_memory\u001b[39m.\u001b[39mpin_memory(data, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_pin_memory_device)\n",
      "File \u001b[1;32mc:\\src\\nlp-project\\venv\\lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py:54\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[1;34m(self, possibly_batched_index)\u001b[0m\n\u001b[0;32m     52\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m     53\u001b[0m     data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset[possibly_batched_index]\n\u001b[1;32m---> 54\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcollate_fn(data)\n",
      "File \u001b[1;32mc:\\src\\nlp-project\\venv\\lib\\site-packages\\transformers\\data\\data_collator.py:582\u001b[0m, in \u001b[0;36mDataCollatorForSeq2Seq.__call__\u001b[1;34m(self, features, return_tensors)\u001b[0m\n\u001b[0;32m    578\u001b[0m     feature[\u001b[39m\"\u001b[39m\u001b[39mlabels\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m (\n\u001b[0;32m    579\u001b[0m         feature[\u001b[39m\"\u001b[39m\u001b[39mlabels\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m+\u001b[39m remainder \u001b[39mif\u001b[39;00m padding_side \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mright\u001b[39m\u001b[39m\"\u001b[39m \u001b[39melse\u001b[39;00m remainder \u001b[39m+\u001b[39m feature[\u001b[39m\"\u001b[39m\u001b[39mlabels\u001b[39m\u001b[39m\"\u001b[39m]\n\u001b[0;32m    580\u001b[0m     )\n\u001b[0;32m    581\u001b[0m \u001b[39melif\u001b[39;00m padding_side \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mright\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[1;32m--> 582\u001b[0m     feature[\u001b[39m\"\u001b[39m\u001b[39mlabels\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39;49mconcatenate([feature[\u001b[39m\"\u001b[39;49m\u001b[39mlabels\u001b[39;49m\u001b[39m\"\u001b[39;49m], remainder])\u001b[39m.\u001b[39mastype(np\u001b[39m.\u001b[39mint64)\n\u001b[0;32m    583\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    584\u001b[0m     feature[\u001b[39m\"\u001b[39m\u001b[39mlabels\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mconcatenate([remainder, feature[\u001b[39m\"\u001b[39m\u001b[39mlabels\u001b[39m\u001b[39m\"\u001b[39m]])\u001b[39m.\u001b[39mastype(np\u001b[39m.\u001b[39mint64)\n",
      "\u001b[1;31mValueError\u001b[0m: all the input arrays must have same number of dimensions, but the array at index 0 has 2 dimension(s) and the array at index 1 has 1 dimension(s)"
     ]
    }
   ],
   "source": [
    "model.train()\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.cuda()\n",
    "model.eval()\n",
    "train_out = trainer.predict(train_data)\n",
    "valid_out = trainer.predict(valid_data)\n",
    "\n",
    "print(\"Train:\", compute_metrics((train_out.predictions, train_data[\"labels\"])))\n",
    "print(\"Valid:\", compute_metrics((valid_out.predictions, valid_data[\"labels\"])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_decode = decoder_tokenizer.batch_decode(train_out.predictions, skip_special_tokens=True)\n",
    "valid_decode = decoder_tokenizer.batch_decode(valid_out.predictions, skip_special_tokens=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_pairs(dataset, generation, sample=5):\n",
    "    assert len(dataset) == len(generation), \"Invalid combination!\"\n",
    "\n",
    "    sample_ids = random.sample(range(len(dataset)), sample)\n",
    "    for i, sid in enumerate(sample_ids):\n",
    "        print(f\"Sentence #{i} [id={sid}]\")\n",
    "        print(\n",
    "            f\"\\tOriginal:  {dataset['source'][sid]}\\n\"\n",
    "            f\"\\tTarget:    {dataset['target'][sid]}\\n\"\n",
    "            f\"\\tGenerated: {generation[sid]}\\n\"\n",
    "        )\n",
    "    return\n",
    "\n",
    "print_pairs(train_data, train_decode, sample=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "NLP",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
